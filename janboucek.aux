\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\citation{deng2009imagenet}
\citation{lin2014microsoft}
\citation{karpathy2016cs231n}
\citation{karpathy2016cs231n}
\citation{simonyan2014very}
\citation{szegedy2015going}
\citation{liu2016ssd}
\citation{redmon2016you}
\citation{liu2016ssd}
\citation{diez2011non}
\citation{schroff2015facenet}
\citation{he2017mask}
\citation{szegedy2015going}
\citation{huang2007labeled}
\citation{wolf2011face}
\citation{cisco}
\citation{goodvision}
\citation{liu2016ssd}
\citation{schroff2015facenet}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Problem statement}{2}{subsection.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces The fisheye camera is mounted in a lamp, therefore the view is directly from above.\relax }}{2}{figure.caption.7}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:stream3}{{1.1}{2}{The fisheye camera is mounted in a lamp, therefore the view is directly from above.\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Overview of methodology}{2}{subsection.8}}
\citation{piccardi2004background}
\citation{optical-flow}
\citation{haar}
\citation{liu2016ssd}
\citation{schroff2015facenet}
\citation{liu2016ssd}
\citation{liu2016ssd}
\citation{schroff2015facenet}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Contribution}{3}{subsection.9}}
\citation{lecun-mnisthandwrittendigit-2010}
\citation{deng2009imagenet}
\citation{Everingham10}
\citation{boiman2008defense,zhang2006svm}
\citation{bosch2007image}
\citation{opelt2004weak}
\citation{chapelle1999support}
\citation{lazebnik2006beyond,nowak2006sampling}
\citation{yang2009linear,bicego2006use}
\citation{munder2006experimental}
\citation{lecun1989backpropagation}
\citation{krizhevsky2012imagenet}
\citation{zeiler2014visualizing}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related work}{5}{section.10}}
\newlabel{sec:related_work}{{2}{5}{Related work}{section.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Classification}{5}{subsection.11}}
\citation{lecun1998gradient}
\citation{schroff2015facenet}
\citation{simonyan2014very}
\citation{liu2016ssd}
\citation{he2016deep}
\citation{hochreiter1998vanishing}
\citation{zagoruyko2016wide}
\citation{xie2017aggregated}
\citation{huang2017densely}
\citation{daubaras2012vehicle,caruso1999vehicle}
\citation{gate2009fast}
\citation{wender20083d,premebida2007lidar}
\citation{kim2005front,wang2003online}
\citation{bertozzi2000stereo,toulminet2006vehicle}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Object Detection}{6}{subsection.12}}
\newlabel{sec:detection}{{2.2}{6}{Object Detection}{subsection.12}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Vehicle detection}{6}{subsubsection.13}}
\citation{huang2018apolloscape,madhavan2017bdd,RobotCarDatasetIJRR,ncarlevaris-2015a}
\citation{tzomakas1998vehicle}
\citation{haar,lienhart2002extended,viola2004robust}
\citation{sun2002real}
\citation{piccardi2004background,horprasert1999statistical}
\citation{naoya1990optical,quenot1992orthogonal,chen2011tracking}
\citation{lowe2004distinctive}
\citation{girshick2014rich,wang2009hog,zhu2006fast,felzenszwalb2010object,dalal2005histograms}
\citation{girshick2016region}
\citation{girshick2014rich}
\citation{carreira2012cpmc}
\citation{simonyan2014very}
\citation{girshick2015fast}
\citation{redmon2016you}
\citation{redmon2017yolo9000,redmon2018yolov3}
\citation{liu2016ssd}
\citation{erhan2014scalable}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Object detection in computer vision}{7}{subsubsection.14}}
\newlabel{sec:object_detection}{{2.2.2}{7}{Object detection in computer vision}{subsubsection.14}{}}
\citation{lin2017focal,li2017fssd,dai2016r}
\citation{sudowe2011efficient}
\citation{gonzalez2012digital}
\citation{naoya1990optical}
\citation{ng2015beyond}
\citation{simonyan2014two}
\citation{karpathy2014large}
\citation{bayona2010stationary,koprinska2001temporal}
\citation{yilmaz2006object}
\citation{kale2015moving}
\citation{comaniciu2003kernel,porikli2005multi,yilmaz2007object,elgammal2002background}
\citation{isard2001bramble}
\citation{kale2015moving}
\citation{veenman1998fast}
\citation{banerjee2008multi}
\citation{zhong2012moving}
\citation{kale2015moving,mae1996object}
\citation{bertinetto2016fully,held2016learning,gladh2016deep,gaidon2016virtual,lee2016globally}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Results on PASCAL VOC2007 test.\relax }}{8}{table.caption.15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Object tracking}{8}{subsection.16}}
\newlabel{sec:object-tracking}{{2.3}{8}{Object tracking}{subsection.16}{}}
\citation{tan2005introduction,benfold2011stable}
\citation{chen2011tracking}
\citation{joshi2012survey,elgammal2002background}
\citation{makris2004bridging}
\citation{khan2003consistent,krumm2000multi,zhao2005real}
\citation{javed2005appearance,porikli2003inter}
\citation{rahimi2004simultaneous}
\citation{makris2004bridging}
\citation{javed2005appearance,huang1997object}
\citation{kettnaker1999bayesian}
\citation{kang2003continuous}
\citation{coifman2007vehicle,kuhne1991freeway}
\citation{arth2007real,du2013automatic}
\citation{matei2011vehicle}
\citation{kwong2009arterial}
\citation{munroe2005multi}
\citation{schroff2015facenet}
\citation{szegedy2016rethinking}
\citation{huang2007labeled}
\citation{wolf2011face}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Reidentification}{9}{subsection.17}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Fisheye camera model}{11}{section.18}}
\newlabel{sec:lens}{{3}{11}{Fisheye camera model}{section.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Frame of the provided video.\relax }}{11}{figure.caption.19}}
\newlabel{fig:stream1}{{3.1}{11}{Frame of the provided video.\relax }{figure.caption.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Scene localization}{11}{subsection.20}}
\newlabel{sec:scene_localization}{{3.1}{11}{Scene localization}{subsection.20}{}}
\newlabel{eq:ellipse}{{1}{12}{Scene localization}{equation.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Camera model}{12}{subsection.25}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces The spherical coordinates of the world.\relax }}{13}{figure.caption.26}}
\newlabel{fig:sphere}{{3.2}{13}{The spherical coordinates of the world.\relax }{figure.caption.26}{}}
\citation{courbon2007generic}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces The provided calibration data.\relax }}{14}{figure.caption.29}}
\newlabel{fig:calibration}{{3.3}{14}{The provided calibration data.\relax }{figure.caption.29}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Linear model}{14}{subsubsection.31}}
\citation{riesenfeld1981homogeneous}
\newlabel{fig:linear_model}{{3.4a}{15}{The linear model of the lens.\relax }{figure.caption.33}{}}
\newlabel{sub@fig:linear_model}{{a}{15}{The linear model of the lens.\relax }{figure.caption.33}{}}
\newlabel{fig:tan_model}{{3.4b}{15}{The tangent model of the lens.\relax }{figure.caption.33}{}}
\newlabel{sub@fig:tan_model}{{b}{15}{The tangent model of the lens.\relax }{figure.caption.33}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Approximation of the calibration data by a linear and tangent model of the lens.\relax }}{15}{figure.caption.33}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Tangent model}{15}{subsubsection.34}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}The city coordinate system}{15}{subsection.36}}
\citation{riesenfeld1981homogeneous}
\citation{deng2009imagenet}
\citation{lin2014microsoft}
\citation{deng2009imagenet}
\citation{lin2014microsoft}
\citation{deng2009imagenet}
\citation{lin2014microsoft}
\@writefile{toc}{\contentsline {section}{\numberline {4}Dataset generation}{17}{section.37}}
\newlabel{sec:classical}{{4}{17}{Dataset generation}{section.37}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Need for a custom dataset}{17}{subsection.38}}
\newlabel{fig:coco0}{{4.1a}{17}{Example of COCO photo for object detection.\relax }{figure.caption.39}{}}
\newlabel{sub@fig:coco0}{{a}{17}{Example of COCO photo for object detection.\relax }{figure.caption.39}{}}
\newlabel{fig:imagenet3}{{4.1b}{17}{Example of ImageNet photo for image classification.\relax }{figure.caption.39}{}}
\newlabel{sub@fig:imagenet3}{{b}{17}{Example of ImageNet photo for image classification.\relax }{figure.caption.39}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces The car class examples in ImageNet \cite  {deng2009imagenet} and COCO \cite  {lin2014microsoft}.\relax }}{17}{figure.caption.39}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Distributed system}{17}{subsection.40}}
\citation{piccardi2004background}
\citation{opencv}
\citation{wren1997pfinder}
\citation{bgs-med1,bgs-med2}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Background subtraction detection}{18}{subsection.41}}
\newlabel{sec:bgs}{{4.3}{18}{Background subtraction detection}{subsection.41}{}}
\newlabel{fig:cut_mean}{{4.2a}{19}{Mean model.\relax }{figure.caption.42}{}}
\newlabel{sub@fig:cut_mean}{{a}{19}{Mean model.\relax }{figure.caption.42}{}}
\newlabel{fig:cut_med}{{4.2b}{19}{Median model.\relax }{figure.caption.42}{}}
\newlabel{sub@fig:cut_med}{{b}{19}{Median model.\relax }{figure.caption.42}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Background model created by the mean and the median approach.\relax }}{19}{figure.caption.42}}
\newlabel{fig:roundabout}{{4.2}{19}{Background model created by the mean and the median approach.\relax }{figure.caption.42}{}}
\newlabel{fig:threshold_mean}{{4.3a}{19}{Mean.\relax }{figure.caption.44}{}}
\newlabel{sub@fig:threshold_mean}{{a}{19}{Mean.\relax }{figure.caption.44}{}}
\newlabel{fig:threshold_med}{{4.3b}{19}{Median.\relax }{figure.caption.44}{}}
\newlabel{sub@fig:threshold_med}{{b}{19}{Median.\relax }{figure.caption.44}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces The difference between the frame and a background shown in a gray-scale.\relax }}{19}{figure.caption.44}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces The histogram of a particular pixel over 100 images with computed medians from the scene in figure \ref  {fig:roundabout}.\relax }}{20}{figure.caption.45}}
\newlabel{fig:pixel_hist}{{4.4}{20}{The histogram of a particular pixel over 100 images with computed medians from the scene in figure \ref {fig:roundabout}.\relax }{figure.caption.45}{}}
\newlabel{fig:frame_for_detection}{{4.5a}{21}{A frame for detection.\relax }{figure.caption.46}{}}
\newlabel{sub@fig:frame_for_detection}{{a}{21}{A frame for detection.\relax }{figure.caption.46}{}}
\newlabel{fig:mask_area}{{4.5b}{21}{The detections and areas of contours.\relax }{figure.caption.46}{}}
\newlabel{sub@fig:mask_area}{{b}{21}{The detections and areas of contours.\relax }{figure.caption.46}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces The background subtraction detection algorithm.\relax }}{21}{figure.caption.46}}
\citation{opencv}
\citation{optical-flow}
\citation{lucas-kanede}
\citation{shi-tomasi}
\citation{harris}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Optical Flow tracking}{22}{subsection.47}}
\newlabel{sec:optical-flow}{{4.4}{22}{Optical Flow tracking}{subsection.47}{}}
\citation{haar}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Classification}{23}{subsection.48}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Semi-supervised dataset generation}{23}{subsection.49}}
\newlabel{sec:data-generation}{{4.6}{23}{Semi-supervised dataset generation}{subsection.49}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces The dialog from the annotation tool.\relax }}{24}{figure.caption.50}}
\newlabel{fig:labeling}{{4.6}{24}{The dialog from the annotation tool.\relax }{figure.caption.50}{}}
\citation{szegedy2015going}
\citation{graves2013speech}
\citation{mit-vision}
\citation{rosenblatt1958perceptron}
\citation{karpathy2016cs231n}
\citation{karpathy2016cs231n}
\@writefile{toc}{\contentsline {section}{\numberline {5}Convolutional Neural Networks}{25}{section.51}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Inspiration by biology}{25}{subsection.52}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Layers}{25}{subsection.53}}
\citation{zeiler2014visualizing}
\citation{karpathy2016cs231n}
\citation{karpathy2016cs231n}
\citation{scherer2010evaluation}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}Convolutional layer}{26}{subsubsection.54}}
\newlabel{fig:conv_layer}{{5.1a}{26}{An example of a convolutional layer.\relax }{figure.caption.55}{}}
\newlabel{sub@fig:conv_layer}{{a}{26}{An example of a convolutional layer.\relax }{figure.caption.55}{}}
\newlabel{fig:neuron}{{5.1b}{26}{Model of a neuron.\relax }{figure.caption.55}{}}
\newlabel{sub@fig:neuron}{{b}{26}{Model of a neuron.\relax }{figure.caption.55}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Examples of neural networks concepts from \cite  {karpathy2016cs231n}.\relax }}{26}{figure.caption.55}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2}Pooling layer}{26}{subsubsection.56}}
\newlabel{fig:conv_layer}{{5.2a}{26}{Pooling downsamples the previous layer.\relax }{figure.caption.57}{}}
\newlabel{sub@fig:conv_layer}{{a}{26}{Pooling downsamples the previous layer.\relax }{figure.caption.57}{}}
\newlabel{fig:neuron}{{5.2b}{26}{Max pooling operation.\relax }{figure.caption.57}{}}
\newlabel{sub@fig:neuron}{{b}{26}{Max pooling operation.\relax }{figure.caption.57}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Examples of pooling concepts from \cite  {karpathy2016cs231n}.\relax }}{26}{figure.caption.57}}
\citation{blumer1989learnability}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.3}Fully connected layer}{27}{subsubsection.58}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.4}Overfitting and dropout layer}{27}{subsubsection.59}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Backpropagation}{27}{subsection.60}}
\newlabel{sec:back-prop}{{5.3}{27}{Backpropagation}{subsection.60}{}}
\citation{hochreiter1998vanishing}
\citation{hinton2006reducing}
\citation{widrow199030}
\citation{abadi2016tensorflow}
\citation{bergstra2011theano}
\citation{seide2016cntk}
\citation{chollet2015keras}
\citation{jia2014caffe}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Transfer learning}{28}{subsection.63}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Frameworks}{28}{subsection.64}}
\citation{deng2009imagenet}
\citation{simonyan2014very}
\citation{li2017fssd}
\citation{szegedy2015going}
\citation{facenet}
\citation{simonyan2014very}
\citation{simonyan2014very}
\citation{simonyan2014very}
\citation{redmon2016you}
\citation{barz2017fast}
\citation{liu2016ssd}
\citation{faster-rcnn}
\citation{ciresan2011flexible}
\citation{krizhevsky2012imagenet}
\citation{simonyan2014very}
\citation{krizhevsky2012imagenet}
\citation{zeiler2014visualizing}
\citation{lecun1989backpropagation}
\citation{simonyan2014very}
\citation{szegedy2015going}
\citation{szegedy2015going}
\citation{szegedy2015going}
\citation{schroff2015facenet}
\citation{deng2009imagenet}
\citation{krizhevsky2012imagenet}
\citation{simonyan2014very}
\@writefile{toc}{\contentsline {section}{\numberline {6}Classification, Detection and Reidentification networks}{29}{section.65}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.0.1}VGG}{29}{subsubsection.66}}
\newlabel{sec:vgg}{{6.0.1}{29}{VGG}{subsubsection.66}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Inception}{29}{subsection.68}}
\newlabel{sec:inception}{{6.1}{29}{Inception}{subsection.68}{}}
\citation{facenet}
\citation{ning2017inception,szegedy2014scalable}
\citation{liu2016ssd}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces The different VGG architectures. The ReLU function is not shown for simplicity. \cite  {simonyan2014very}\relax }}{30}{figure.caption.67}}
\newlabel{fig:vgg}{{6.1}{30}{The different VGG architectures. The ReLU function is not shown for simplicity. \cite {simonyan2014very}\relax }{figure.caption.67}{}}
\citation{liu2016ssd}
\citation{redmon2016you}
\citation{liu2016ssd}
\citation{redmon2016you}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces Inception module \cite  {szegedy2015going} with dimension reductions.\relax }}{31}{figure.caption.69}}
\newlabel{fig:inception-module}{{6.2}{31}{Inception module \cite {szegedy2015going} with dimension reductions.\relax }{figure.caption.69}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}SSD network for detection}{31}{subsection.70}}
\newlabel{sec:ssd}{{6.2}{31}{SSD network for detection}{subsection.70}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.1}Architecture}{31}{subsubsection.71}}
\citation{liu2016ssd}
\citation{liu2016ssd}
\citation{li2017fssd}
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces Comparison of the SSD\cite  {liu2016ssd}(300x300) and YOLO\cite  {redmon2016you}(448x448) architectures.\relax }}{32}{figure.caption.72}}
\newlabel{fig:ssd_vs_yolo}{{6.3}{32}{Comparison of the SSD\cite {liu2016ssd}(300x300) and YOLO\cite {redmon2016you}(448x448) architectures.\relax }{figure.caption.72}{}}
\newlabel{fig:ssd_detection}{{6.4a}{32}{SSD prediction.\relax }{figure.caption.74}{}}
\newlabel{sub@fig:ssd_detection}{{a}{32}{SSD prediction.\relax }{figure.caption.74}{}}
\newlabel{fig:ssd4}{{6.4b}{32}{8 $\times $ 8 feature map.\relax }{figure.caption.74}{}}
\newlabel{sub@fig:ssd4}{{b}{32}{8 $\times $ 8 feature map.\relax }{figure.caption.74}{}}
\newlabel{fig:ssd8}{{6.4c}{32}{The predicted offsets.\relax }{figure.caption.74}{}}
\newlabel{sub@fig:ssd8}{{c}{32}{The predicted offsets.\relax }{figure.caption.74}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.4}{\ignorespaces The SSD \cite  {liu2016ssd} predictions.\relax }}{32}{figure.caption.74}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.2}Default boxes and aspect ratios}{32}{subsubsection.73}}
\citation{girshick2015fast}
\citation{erhan2014scalable}
\citation{diez2011non}
\citation{diez2011non}
\citation{tan2005introduction}
\citation{schroff2015facenet}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Loss}{33}{subsection.75}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.3.1}Training}{33}{subsubsection.77}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Non-maxima suppression}{33}{subsection.78}}
\citation{schroff2015facenet}
\citation{schroff2015facenet}
\citation{zeiler2014visualizing}
\citation{szegedy2015going}
\citation{szegedy2015going}
\newlabel{fig:nms1}{{6.5a}{34}{Predictions before applying nms.\relax }{figure.caption.79}{}}
\newlabel{sub@fig:nms1}{{a}{34}{Predictions before applying nms.\relax }{figure.caption.79}{}}
\newlabel{fig:nms2}{{6.5b}{34}{Predictions after applying nms.\relax }{figure.caption.79}{}}
\newlabel{sub@fig:nms2}{{b}{34}{Predictions after applying nms.\relax }{figure.caption.79}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.5}{\ignorespaces Non maxima suppression\cite  {diez2011non} keeps a single prediction.\relax }}{34}{figure.caption.79}}
\newlabel{fig:nms}{{6.5}{34}{Non maxima suppression\cite {diez2011non} keeps a single prediction.\relax }{figure.caption.79}{}}
\newlabel{fig:facenet_structure}{{6.6a}{34}{The model structure.\relax }{figure.caption.82}{}}
\newlabel{sub@fig:facenet_structure}{{a}{34}{The model structure.\relax }{figure.caption.82}{}}
\newlabel{fig:triplet_loss}{{6.6b}{34}{The learning objective.\relax }{figure.caption.82}{}}
\newlabel{sub@fig:triplet_loss}{{b}{34}{The learning objective.\relax }{figure.caption.82}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.6}{\ignorespaces The Facenet \cite  {schroff2015facenet}.\relax }}{34}{figure.caption.82}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5}Facenet for reidentification}{34}{subsection.80}}
\newlabel{sec:facenet}{{6.5}{34}{Facenet for reidentification}{subsection.80}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.5.1}Architecture}{34}{subsubsection.81}}
\citation{wst2008deeply,taigman2014deepface}
\citation{szegedy2015going}
\citation{chen2017beyond}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.5.2}Training}{35}{subsubsection.83}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6}Multi camera tracking}{36}{subsection.86}}
\newlabel{sec:multi-camera-tracking}{{6.6}{36}{Multi camera tracking}{subsection.86}{}}
\citation{abadi2016tensorflow}
\citation{chollet2015keras}
\citation{opencv}
\citation{walt2011numpy}
\citation{he2017mask}
\citation{he2017mask}
\citation{he2017mask}
\citation{lin2014microsoft}
\@writefile{toc}{\contentsline {section}{\numberline {7}Implementation}{37}{section.87}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Mask R-CNN segmentation}{37}{subsection.88}}
\newlabel{sec:mask-rcnn}{{7.1}{37}{Mask R-CNN segmentation}{subsection.88}{}}
\newlabel{fig:mask-street-cam}{{7.1a}{37}{Mask R-CNN on a standard street camera.\relax }{figure.caption.89}{}}
\newlabel{sub@fig:mask-street-cam}{{a}{37}{Mask R-CNN on a standard street camera.\relax }{figure.caption.89}{}}
\newlabel{fig:mask-omni-cam}{{7.1b}{37}{Mask R-CNN on a fisheye camera has problems recognizing vehicles from the top.\relax }{figure.caption.89}{}}
\newlabel{sub@fig:mask-omni-cam}{{b}{37}{Mask R-CNN on a fisheye camera has problems recognizing vehicles from the top.\relax }{figure.caption.89}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces Examples of Mask R-CNN network \cite  {he2017mask}.\relax }}{37}{figure.caption.89}}
\newlabel{fig:facenet}{{7.1}{37}{Examples of Mask R-CNN network \cite {he2017mask}.\relax }{figure.caption.89}{}}
\citation{liu2016ssd}
\citation{faster-rcnn}
\citation{redmon2016you}
\citation{ssd_keras}
\newlabel{fig:td_frame}{{7.2a}{38}{A frame from the street camera.\\ \quad \relax }{figure.caption.92}{}}
\newlabel{sub@fig:td_frame}{{a}{38}{A frame from the street camera.\\ \quad \relax }{figure.caption.92}{}}
\newlabel{fig:td_black}{{7.2b}{38}{Temporal difference highlights moving objects.\relax }{figure.caption.92}{}}
\newlabel{sub@fig:td_black}{{b}{38}{Temporal difference highlights moving objects.\relax }{figure.caption.92}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.2}{\ignorespaces Temporal difference helps to detect moving objects.\relax }}{38}{figure.caption.92}}
\newlabel{fig:td}{{7.2}{38}{Temporal difference helps to detect moving objects.\relax }{figure.caption.92}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}SSD detector}{38}{subsection.90}}
\newlabel{sec:ssd-implementation}{{7.2}{38}{SSD detector}{subsection.90}{}}
\citation{walt2011numpy}
\citation{opencv}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.2.1}Temporal difference}{39}{subsubsection.91}}
\citation{cao2018feature}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.2.2}Architecture}{40}{subsubsection.94}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.2.3}Dataset}{40}{subsubsection.95}}
\newlabel{sec:ssd-dataset}{{7.2.3}{40}{Dataset}{subsubsection.95}{}}
\citation{deng2009imagenet}
\citation{lin2014microsoft}
\citation{real2017youtube}
\citation{kingma2014adam}
\citation{ssd_keras}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.2.4}Data augmentation}{41}{subsubsection.96}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.2.5}Training}{41}{subsubsection.97}}
\newlabel{fig:ssd_mAP}{{7.3a}{42}{The mean average precision on validation set.\relax }{figure.caption.98}{}}
\newlabel{sub@fig:ssd_mAP}{{a}{42}{The mean average precision on validation set.\relax }{figure.caption.98}{}}
\newlabel{fig:ssd_loss}{{7.3b}{42}{The loss on the training set.\relax }{figure.caption.98}{}}
\newlabel{sub@fig:ssd_loss}{{b}{42}{The loss on the training set.\relax }{figure.caption.98}{}}
\newlabel{fig:ssd_val_loss}{{7.3c}{42}{The loss on the validation set.\relax }{figure.caption.98}{}}
\newlabel{sub@fig:ssd_val_loss}{{c}{42}{The loss on the validation set.\relax }{figure.caption.98}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.3}{\ignorespaces The process of training the 4 channel input SSD network. The training was performed on the NVIDIA GeForce GTX 1080 for 4 days.\relax }}{42}{figure.caption.98}}
\newlabel{fig:ssd_training}{{7.3}{42}{The process of training the 4 channel input SSD network. The training was performed on the NVIDIA GeForce GTX 1080 for 4 days.\relax }{figure.caption.98}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Single camera tracking}{42}{subsection.99}}
\citation{shi-tomasi}
\citation{optical-flow}
\citation{lucas-kanede}
\citation{szegedy2015going}
\citation{huang2007labeled}
\citation{wolf2011face}
\citation{szegedy2015going}
\citation{huang2007labeled}
\citation{wolf2011face}
\citation{schroff2015facenet}
\citation{facenet}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.1}Seeding}{43}{subsubsection.100}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.2}Displacement}{43}{subsubsection.101}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.3}Matching}{43}{subsubsection.102}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4}Similarity}{43}{subsection.103}}
\newlabel{sec:similarity}{{7.4}{43}{Similarity}{subsection.103}{}}
\citation{standford}
\newlabel{fig:facenet_table}{{7.4a}{44}{Mean VAL at $10^{-3}$ FAR.\relax }{figure.caption.104}{}}
\newlabel{sub@fig:facenet_table}{{a}{44}{Mean VAL at $10^{-3}$ FAR.\relax }{figure.caption.104}{}}
\newlabel{fig:triplet_loss}{{7.4b}{44}{Comparison of different DNN architectures.\relax }{figure.caption.104}{}}
\newlabel{sub@fig:triplet_loss}{{b}{44}{Comparison of different DNN architectures.\relax }{figure.caption.104}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.4}{\ignorespaces Comparison of various facenet\cite  {szegedy2015going} base networks evaluated on Labeled faces in the wild\cite  {huang2007labeled} and YouTube faces\cite  {wolf2011face} datasets.\relax }}{44}{figure.caption.104}}
\newlabel{fig:facenet}{{7.4}{44}{Comparison of various facenet\cite {szegedy2015going} base networks evaluated on Labeled faces in the wild\cite {huang2007labeled} and YouTube faces\cite {wolf2011face} datasets.\relax }{figure.caption.104}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.4.1}Dataset}{44}{subsubsection.105}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.5}{\ignorespaces An example of a one object in a training set.\relax }}{44}{figure.caption.106}}
\newlabel{fig:facenet-labeling}{{7.5}{44}{An example of a one object in a training set.\relax }{figure.caption.106}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.4.2}Problems with the dataset}{45}{subsubsection.107}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.4.3}Improving the dataset}{45}{subsubsection.108}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.4.4}Training}{45}{subsubsection.109}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.6}{\ignorespaces Accuracy during the facenet training.\relax }}{46}{figure.caption.110}}
\newlabel{fig:facenet_training}{{7.6}{46}{Accuracy during the facenet training.\relax }{figure.caption.110}{}}
\newlabel{fig:facenet}{{7.7a}{46}{True positive rate.\relax }{figure.caption.111}{}}
\newlabel{sub@fig:facenet}{{a}{46}{True positive rate.\relax }{figure.caption.111}{}}
\newlabel{fig:facenet}{{7.7b}{46}{True negative rate.\relax }{figure.caption.111}{}}
\newlabel{sub@fig:facenet}{{b}{46}{True negative rate.\relax }{figure.caption.111}{}}
\newlabel{fig:facenet}{{7.7c}{46}{False positive rate.\relax }{figure.caption.111}{}}
\newlabel{sub@fig:facenet}{{c}{46}{False positive rate.\relax }{figure.caption.111}{}}
\newlabel{fig:facenet}{{7.7d}{46}{False negative rate.\relax }{figure.caption.111}{}}
\newlabel{sub@fig:facenet}{{d}{46}{False negative rate.\relax }{figure.caption.111}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.7}{\ignorespaces Additional information about the Facenet training. The training was performed on the NVIDIA GeForce GTX 1080 for 12 hours.\relax }}{46}{figure.caption.111}}
\newlabel{fig:facenet_training_additional}{{7.7}{46}{Additional information about the Facenet training. The training was performed on the NVIDIA GeForce GTX 1080 for 12 hours.\relax }{figure.caption.111}{}}
\citation{wold1987principal}
\citation{maaten2008visualizing}
\citation{pedregosa2011scikit}
\@writefile{lof}{\contentsline {figure}{\numberline {7.8}{\ignorespaces Visualization of facenet embeddings using the T-SNE dimensionality reduction.\relax }}{47}{figure.caption.113}}
\newlabel{fig:facenet_training}{{7.8}{47}{Visualization of facenet embeddings using the T-SNE dimensionality reduction.\relax }{figure.caption.113}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.4.5}T-SNE visualization}{47}{subsubsection.112}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5}City representation}{47}{subsection.114}}
\newlabel{sec:city-representation}{{7.5}{47}{City representation}{subsection.114}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.9}{\ignorespaces An example of a part of city representation with transition probabilities.\relax }}{48}{figure.caption.115}}
\newlabel{fig:intersection}{{7.9}{48}{An example of a part of city representation with transition probabilities.\relax }{figure.caption.115}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.5.1}Reidentification}{49}{subsubsection.116}}
\newlabel{sec:reidentification}{{7.5.1}{49}{Reidentification}{subsubsection.116}{}}
\newlabel{eq:score-reid}{{17}{49}{Reidentification}{equation.117}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.5.2}Decreasing computational demands}{50}{subsubsection.118}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.6}Multi camera tracking}{50}{subsection.120}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Evaluation}{51}{section.121}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Mean average precision.}{51}{subsection.122}}
\newlabel{sec:mAP}{{8.1}{51}{Mean average precision}{subsection.122}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.1}{\ignorespaces Example of arbitrary precision-recall curve.\relax }}{52}{figure.caption.126}}
\newlabel{fig:precision-recall}{{8.1}{52}{Example of arbitrary precision-recall curve.\relax }{figure.caption.126}{}}
\citation{liu2016ssd}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}SSD object detection}{53}{subsection.127}}
\newlabel{sec:ssd-evaluation}{{8.2}{53}{SSD object detection}{subsection.127}{}}
\newlabel{fig:ssd_mAP}{{8.2a}{53}{The mean average precision on validation set.\relax }{figure.caption.128}{}}
\newlabel{sub@fig:ssd_mAP}{{a}{53}{The mean average precision on validation set.\relax }{figure.caption.128}{}}
\newlabel{fig:ssd_loss}{{8.2b}{53}{The loss on the training set.\relax }{figure.caption.128}{}}
\newlabel{sub@fig:ssd_loss}{{b}{53}{The loss on the training set.\relax }{figure.caption.128}{}}
\newlabel{fig:ssd_val_loss}{{8.2c}{53}{The loss on the validation set.\relax }{figure.caption.128}{}}
\newlabel{sub@fig:ssd_val_loss}{{c}{53}{The loss on the validation set.\relax }{figure.caption.128}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.2}{\ignorespaces The process of training the introduced 4 channel SSD (orange) and the 3 channel SSD (blue) networks. The training was performed on the NVIDIA GeForce GTX 1080 for 1 day. The graph shows, that the presented solution performs much better than the state of the art SSD.\relax }}{53}{figure.caption.128}}
\newlabel{fig:ssd_training}{{8.2}{53}{The process of training the introduced 4 channel SSD (orange) and the 3 channel SSD (blue) networks. The training was performed on the NVIDIA GeForce GTX 1080 for 1 day. The graph shows, that the presented solution performs much better than the state of the art SSD.\relax }{figure.caption.128}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Results on the custom dataset from the section \ref  {sec:ssd-dataset} show, that the introduced RGBD architecture is more accurate, than the standard SSD.\relax }}{54}{table.caption.129}}
\newlabel{tab:ssd_camparison}{{2}{54}{Results on the custom dataset from the section \ref {sec:ssd-dataset} show, that the introduced RGBD architecture is more accurate, than the standard SSD.\relax }{table.caption.129}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3}Facenet similarity}{54}{subsection.130}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.3.1}Evaluation metrics}{54}{subsubsection.131}}
\newlabel{sec:similarity-eval}{{8.3.1}{54}{Evaluation metrics}{subsubsection.131}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.3.2}Results}{54}{subsubsection.132}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Final results of the facenet training after 12 hours on NVIDIA GeForce GTX 1080.\relax }}{54}{table.caption.133}}
\newlabel{tab:facenet}{{3}{54}{Final results of the facenet training after 12 hours on NVIDIA GeForce GTX 1080.\relax }{table.caption.133}{}}
\citation{munroe2005multi,psyllos2011vehicle,lai2001vehicle}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.3.3}Comparison to state of the art}{55}{subsubsection.134}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.4}Multi camera tracking experiment}{55}{subsection.135}}
\newlabel{sec:multi-camera-tracking}{{8.4}{55}{Multi camera tracking experiment}{subsection.135}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.4.1}Evaluation measurement}{55}{subsubsection.136}}
\citation{coifman2007vehicle,kuhne1991freeway}
\citation{arth2007real,du2013automatic}
\citation{matei2011vehicle}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.4.2}Results}{56}{subsubsection.137}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.4.3}Comparison to state of the art}{56}{subsubsection.138}}
\@writefile{toc}{\contentsline {section}{\numberline {9}Discussion}{57}{section.139}}
\citation{liu2016ssd}
\citation{liu2016ssd}
\citation{schroff2015facenet}
\@writefile{toc}{\contentsline {section}{\numberline {10}Conclusion}{58}{section.140}}
\citation{chen2017beyond}
\citation{lin2017focal,redmon2018yolov3}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1}Future work}{59}{subsection.141}}
\bibstyle{plain}
\bibdata{src/ref}
\bibcite{goodvision}{{1}{}{{}}{{}}}
\bibcite{abadi2016tensorflow}{{2}{}{{}}{{}}}
\bibcite{arth2007real}{{3}{}{{}}{{}}}
\bibcite{banerjee2008multi}{{4}{}{{}}{{}}}
\bibcite{barz2017fast}{{5}{}{{}}{{}}}
\bibcite{bayona2010stationary}{{6}{}{{}}{{}}}
\bibcite{optical-flow}{{7}{}{{}}{{}}}
\bibcite{benfold2011stable}{{8}{}{{}}{{}}}
\bibcite{bergstra2011theano}{{9}{}{{}}{{}}}
\bibcite{bertinetto2016fully}{{10}{}{{}}{{}}}
\bibcite{bertozzi2000stereo}{{11}{}{{}}{{}}}
\bibcite{bicego2006use}{{12}{}{{}}{{}}}
\bibcite{blumer1989learnability}{{13}{}{{}}{{}}}
\bibcite{boiman2008defense}{{14}{}{{}}{{}}}
\@writefile{toc}{\contentsline {section}{References}{61}{subsection.141}}
\bibcite{bosch2007image}{{15}{}{{}}{{}}}
\bibcite{opencv}{{16}{}{{}}{{}}}
\bibcite{cao2018feature}{{17}{}{{}}{{}}}
\bibcite{ncarlevaris-2015a}{{18}{}{{}}{{}}}
\bibcite{carreira2012cpmc}{{19}{}{{}}{{}}}
\bibcite{caruso1999vehicle}{{20}{}{{}}{{}}}
\bibcite{chapelle1999support}{{21}{}{{}}{{}}}
\bibcite{chen2017beyond}{{22}{}{{}}{{}}}
\bibcite{chen2011tracking}{{23}{}{{}}{{}}}
\bibcite{chollet2015keras}{{24}{}{{}}{{}}}
\bibcite{ciresan2011flexible}{{25}{}{{}}{{}}}
\bibcite{coifman2007vehicle}{{26}{}{{}}{{}}}
\bibcite{comaniciu2003kernel}{{27}{}{{}}{{}}}
\bibcite{courbon2007generic}{{28}{}{{}}{{}}}
\bibcite{bgs-med2}{{29}{}{{}}{{}}}
\bibcite{dai2016r}{{30}{}{{}}{{}}}
\bibcite{dalal2005histograms}{{31}{}{{}}{{}}}
\bibcite{daubaras2012vehicle}{{32}{}{{}}{{}}}
\bibcite{deng2009imagenet}{{33}{}{{}}{{}}}
\bibcite{diez2011non}{{34}{}{{}}{{}}}
\bibcite{du2013automatic}{{35}{}{{}}{{}}}
\bibcite{elgammal2002background}{{36}{}{{}}{{}}}
\bibcite{erhan2014scalable}{{37}{}{{}}{{}}}
\bibcite{Everingham10}{{38}{}{{}}{{}}}
\bibcite{felzenszwalb2010object}{{39}{}{{}}{{}}}
\bibcite{facenet}{{40}{}{{}}{{}}}
\bibcite{ssd_keras}{{41}{}{{}}{{}}}
\bibcite{gaidon2016virtual}{{42}{}{{}}{{}}}
\bibcite{gate2009fast}{{43}{}{{}}{{}}}
\bibcite{cisco}{{44}{}{{}}{{}}}
\bibcite{girshick2015fast}{{45}{}{{}}{{}}}
\bibcite{girshick2014rich}{{46}{}{{}}{{}}}
\bibcite{girshick2016region}{{47}{}{{}}{{}}}
\bibcite{gladh2016deep}{{48}{}{{}}{{}}}
\bibcite{gonzalez2012digital}{{49}{}{{}}{{}}}
\bibcite{graves2013speech}{{50}{}{{}}{{}}}
\bibcite{harris}{{51}{}{{}}{{}}}
\bibcite{haar}{{52}{}{{}}{{}}}
\bibcite{he2017mask}{{53}{}{{}}{{}}}
\bibcite{he2016deep}{{54}{}{{}}{{}}}
\bibcite{held2016learning}{{55}{}{{}}{{}}}
\bibcite{hinton2006reducing}{{56}{}{{}}{{}}}
\bibcite{hochreiter1998vanishing}{{57}{}{{}}{{}}}
\bibcite{horprasert1999statistical}{{58}{}{{}}{{}}}
\bibcite{huang2017densely}{{59}{}{{}}{{}}}
\bibcite{huang2007labeled}{{60}{}{{}}{{}}}
\bibcite{huang1997object}{{61}{}{{}}{{}}}
\bibcite{huang2018apolloscape}{{62}{}{{}}{{}}}
\bibcite{isard2001bramble}{{63}{}{{}}{{}}}
\bibcite{javed2005appearance}{{64}{}{{}}{{}}}
\bibcite{jia2014caffe}{{65}{}{{}}{{}}}
\bibcite{joshi2012survey}{{66}{}{{}}{{}}}
\bibcite{kale2015moving}{{67}{}{{}}{{}}}
\bibcite{kang2003continuous}{{68}{}{{}}{{}}}
\bibcite{karpathy2016cs231n}{{69}{}{{}}{{}}}
\bibcite{karpathy2014large}{{70}{}{{}}{{}}}
\bibcite{kettnaker1999bayesian}{{71}{}{{}}{{}}}
\bibcite{khan2003consistent}{{72}{}{{}}{{}}}
\bibcite{kim2005front}{{73}{}{{}}{{}}}
\bibcite{kingma2014adam}{{74}{}{{}}{{}}}
\bibcite{koprinska2001temporal}{{75}{}{{}}{{}}}
\bibcite{standford}{{76}{}{{}}{{}}}
\bibcite{krizhevsky2012imagenet}{{77}{}{{}}{{}}}
\bibcite{krumm2000multi}{{78}{}{{}}{{}}}
\bibcite{kuhne1991freeway}{{79}{}{{}}{{}}}
\bibcite{kwong2009arterial}{{80}{}{{}}{{}}}
\bibcite{lai2001vehicle}{{81}{}{{}}{{}}}
\bibcite{lazebnik2006beyond}{{82}{}{{}}{{}}}
\bibcite{lecun1989backpropagation}{{83}{}{{}}{{}}}
\bibcite{lecun1998gradient}{{84}{}{{}}{{}}}
\bibcite{lecun-mnisthandwrittendigit-2010}{{85}{}{{}}{{}}}
\bibcite{lee2016globally}{{86}{}{{}}{{}}}
\bibcite{li2017fssd}{{87}{}{{}}{{}}}
\bibcite{lienhart2002extended}{{88}{}{{}}{{}}}
\bibcite{lin2017focal}{{89}{}{{}}{{}}}
\bibcite{lin2014microsoft}{{90}{}{{}}{{}}}
\bibcite{liu2016ssd}{{91}{}{{}}{{}}}
\bibcite{bgs-med1}{{92}{}{{}}{{}}}
\bibcite{lowe2004distinctive}{{93}{}{{}}{{}}}
\bibcite{lucas-kanede}{{94}{}{{}}{{}}}
\bibcite{maaten2008visualizing}{{95}{}{{}}{{}}}
\bibcite{RobotCarDatasetIJRR}{{96}{}{{}}{{}}}
\bibcite{madhavan2017bdd}{{97}{}{{}}{{}}}
\bibcite{mae1996object}{{98}{}{{}}{{}}}
\bibcite{makris2004bridging}{{99}{}{{}}{{}}}
\bibcite{matei2011vehicle}{{100}{}{{}}{{}}}
\bibcite{munder2006experimental}{{101}{}{{}}{{}}}
\bibcite{munroe2005multi}{{102}{}{{}}{{}}}
\bibcite{naoya1990optical}{{103}{}{{}}{{}}}
\bibcite{ng2015beyond}{{104}{}{{}}{{}}}
\bibcite{ning2017inception}{{105}{}{{}}{{}}}
\bibcite{nowak2006sampling}{{106}{}{{}}{{}}}
\bibcite{opelt2004weak}{{107}{}{{}}{{}}}
\bibcite{pedregosa2011scikit}{{108}{}{{}}{{}}}
\bibcite{piccardi2004background}{{109}{}{{}}{{}}}
\bibcite{porikli2003inter}{{110}{}{{}}{{}}}
\bibcite{porikli2005multi}{{111}{}{{}}{{}}}
\bibcite{premebida2007lidar}{{112}{}{{}}{{}}}
\bibcite{psyllos2011vehicle}{{113}{}{{}}{{}}}
\bibcite{quenot1992orthogonal}{{114}{}{{}}{{}}}
\bibcite{rahimi2004simultaneous}{{115}{}{{}}{{}}}
\bibcite{real2017youtube}{{116}{}{{}}{{}}}
\bibcite{redmon2016you}{{117}{}{{}}{{}}}
\bibcite{redmon2017yolo9000}{{118}{}{{}}{{}}}
\bibcite{redmon2018yolov3}{{119}{}{{}}{{}}}
\bibcite{faster-rcnn}{{120}{}{{}}{{}}}
\bibcite{riesenfeld1981homogeneous}{{121}{}{{}}{{}}}
\bibcite{rosenblatt1958perceptron}{{122}{}{{}}{{}}}
\bibcite{scherer2010evaluation}{{123}{}{{}}{{}}}
\bibcite{schroff2015facenet}{{124}{}{{}}{{}}}
\bibcite{seide2016cntk}{{125}{}{{}}{{}}}
\bibcite{shi-tomasi}{{126}{}{{}}{{}}}
\bibcite{simonyan2014two}{{127}{}{{}}{{}}}
\bibcite{simonyan2014very}{{128}{}{{}}{{}}}
\bibcite{sudowe2011efficient}{{129}{}{{}}{{}}}
\bibcite{sun2002real}{{130}{}{{}}{{}}}
\bibcite{mit-vision}{{131}{}{{}}{{}}}
\bibcite{szegedy2015going}{{132}{}{{}}{{}}}
\bibcite{szegedy2014scalable}{{133}{}{{}}{{}}}
\bibcite{szegedy2016rethinking}{{134}{}{{}}{{}}}
\bibcite{taigman2014deepface}{{135}{}{{}}{{}}}
\bibcite{tan2005introduction}{{136}{}{{}}{{}}}
\bibcite{toulminet2006vehicle}{{137}{}{{}}{{}}}
\bibcite{tzomakas1998vehicle}{{138}{}{{}}{{}}}
\bibcite{veenman1998fast}{{139}{}{{}}{{}}}
\bibcite{viola2004robust}{{140}{}{{}}{{}}}
\bibcite{walt2011numpy}{{141}{}{{}}{{}}}
\bibcite{wang2003online}{{142}{}{{}}{{}}}
\bibcite{wang2009hog}{{143}{}{{}}{{}}}
\bibcite{wender20083d}{{144}{}{{}}{{}}}
\bibcite{widrow199030}{{145}{}{{}}{{}}}
\bibcite{wold1987principal}{{146}{}{{}}{{}}}
\bibcite{wolf2011face}{{147}{}{{}}{{}}}
\bibcite{wren1997pfinder}{{148}{}{{}}{{}}}
\bibcite{wst2008deeply}{{149}{}{{}}{{}}}
\bibcite{xie2017aggregated}{{150}{}{{}}{{}}}
\bibcite{yang2009linear}{{151}{}{{}}{{}}}
\bibcite{yilmaz2007object}{{152}{}{{}}{{}}}
\bibcite{yilmaz2006object}{{153}{}{{}}{{}}}
\bibcite{zagoruyko2016wide}{{154}{}{{}}{{}}}
\bibcite{zeiler2014visualizing}{{155}{}{{}}{{}}}
\bibcite{zhang2006svm}{{156}{}{{}}{{}}}
\bibcite{zhao2005real}{{157}{}{{}}{{}}}
\bibcite{zhong2012moving}{{158}{}{{}}{{}}}
\bibcite{zhu2006fast}{{159}{}{{}}{{}}}
\newlabel{LastPage}{{}{72}{}{page.88}{}}
\xdef\lastpage@lastpage{72}
\xdef\lastpage@lastpageHy{88}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
