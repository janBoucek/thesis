\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\citation{krizhevsky2012imagenet}
\citation{lin2014microsoft}
\citation{karpathy2016cs231n}
\citation{karpathy2016cs231n}
\citation{simonyan2014very}
\citation{liu2016ssd}
\citation{redmon2016you}
\citation{diez2011non}
\citation{schroff2015facenet}
\citation{he2017mask}
\citation{szegedy2016rethinking}
\citation{huang2007labeled}
\citation{wolf2011face}
\citation{cisco}
\citation{liu2016ssd}
\citation{schroff2015facenet}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Problem statement}{2}{subsection.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces The fisheye camera is mounted in a lamp, so the view is directly from above.\relax }}{2}{figure.caption.7}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:stream3}{{1.1}{2}{The fisheye camera is mounted in a lamp, so the view is directly from above.\relax }{figure.caption.7}{}}
\citation{piccardi2004background}
\citation{optical-flow}
\citation{haar}
\citation{liu2016ssd}
\citation{schroff2015facenet}
\citation{liu2016ssd}
\citation{liu2016ssd}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Overview of methodology}{3}{subsection.8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Contribution}{3}{subsection.9}}
\citation{schroff2015facenet}
\citation{lecun-mnisthandwrittendigit-2010}
\citation{deng2009imagenet}
\citation{Everingham10}
\citation{boiman2008defense,zhang2006svm}
\citation{bosch2007image}
\citation{opelt2004weak}
\citation{chapelle1999support}
\citation{lazebnik2006beyond,nowak2006sampling}
\citation{yang2009linear,bicego2006use}
\citation{munder2006experimental}
\citation{lecun1989backpropagation}
\citation{krizhevsky2012imagenet}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related work}{5}{section.10}}
\newlabel{sec:related_work}{{2}{5}{Related work}{section.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Classification}{5}{subsection.11}}
\citation{zeiler2014visualizing}
\citation{lecun1998gradient}
\citation{schroff2015facenet}
\citation{simonyan2014very}
\citation{liu2016ssd}
\citation{he2016deep}
\citation{zagoruyko2016wide}
\citation{xie2017aggregated}
\citation{huang2017densely}
\citation{daubaras2012vehicle,caruso1999vehicle}
\citation{gate2009fast}
\citation{wender20083d,premebida2007lidar}
\citation{kim2005front,wang2003online}
\citation{bertozzi2000stereo,toulminet2006vehicle}
\citation{apollo-scape,madhavan2017bdd,RobotCarDatasetIJRR,ncarlevaris-2015a}
\citation{tzomakas1998vehicle}
\citation{haar,lienhart2002extended,viola2004robust}
\citation{sun2002real}
\citation{piccardi2004background,horprasert1999statistical}
\citation{naoya1990optical,quenot1992orthogonal,chen2011tracking}
\citation{lowe2004distinctive}
\citation{girshick2014rich,wang2009hog,zhu2006fast,felzenszwalb2010object,dalal2005histograms}
\citation{girshick2016region}
\citation{DBLP:journals/corr/GirshickDDM13}
\citation{carreira2012cpmc}
\citation{simonyan2014very}
\citation{girshick2015fast}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Object Detection}{7}{subsection.12}}
\newlabel{sec:detection}{{2.2}{7}{Object Detection}{subsection.12}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Vehicle detection}{7}{subsubsection.13}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Object detection in computer vision}{7}{subsubsection.14}}
\newlabel{sec:object_detection}{{2.2.2}{7}{Object detection in computer vision}{subsubsection.14}{}}
\citation{redmon2016you}
\citation{redmon2017yolo9000,redmon2018yolov3}
\citation{liu2016ssd}
\citation{erhan2014scalable}
\citation{lin2017focal,li2017fssd,dai2016r}
\citation{sudowe2011efficient}
\citation{gonzalez2012digital}
\citation{naoya1990optical}
\citation{karpathy2014large}
\citation{bayona2010stationary,koprinska2001temporal}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Results on PASCAL VOC2007 test.\relax }}{8}{table.caption.15}}
\citation{yilmaz2006object}
\citation{kale2015moving}
\citation{comaniciu2003kernel,porikli2005multi,yilmaz2007object,elgammal2002background}
\citation{isard2001bramble}
\citation{kale2015moving}
\citation{veenman1998fast}
\citation{banerjee2008multi}
\citation{zhong2012moving}
\citation{kale2015moving,mae1996object}
\citation{bertinetto2016fully,held2016learning,gladh2016deep,gaidon2016virtual,lee2016globally}
\citation{tan2005introduction,benfold2011stable}
\citation{chen2011tracking}
\citation{joshi2012survey,elgammal2002background}
\citation{makris2004bridging}
\citation{khan2003consistent,krumm2000multi,zhao2005real}
\citation{javed2005appearance,porikli2003inter}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Object tracking}{9}{subsection.16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Reidentification}{9}{subsection.17}}
\citation{rahimi2004simultaneous}
\citation{makris2004bridging}
\citation{javed2005appearance,huang1997object}
\citation{kettnaker1999bayesian}
\citation{kang2003continuous}
\citation{coifman2007vehicle,kuhne1991freeway}
\citation{arth2007real,du2013automatic}
\citation{matei2011vehicle}
\citation{kwong2009arterial}
\citation{schroff2015facenet}
\citation{szegedy2016rethinking}
\citation{huang2007labeled}
\citation{wolf2011face}
\@writefile{toc}{\contentsline {section}{\numberline {3}Fisheye camera model}{11}{section.18}}
\newlabel{sec:lens}{{3}{11}{Fisheye camera model}{section.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Frame of the provided video.\relax }}{11}{figure.caption.19}}
\newlabel{fig:stream1}{{3.1}{11}{Frame of the provided video.\relax }{figure.caption.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Scene localization}{11}{subsection.20}}
\newlabel{sec:scene_localization}{{3.1}{11}{Scene localization}{subsection.20}{}}
\citation{lukacs1997real}
\newlabel{eq:ellipse}{{1}{12}{Scene localization}{equation.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Camera model}{13}{subsection.25}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces The spherical coordinates of the world.\relax }}{13}{figure.caption.26}}
\newlabel{fig:sphere}{{3.2}{13}{The spherical coordinates of the world.\relax }{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces The provided calibration data.\relax }}{14}{figure.caption.29}}
\newlabel{fig:calibration}{{3.3}{14}{The provided calibration data.\relax }{figure.caption.29}{}}
\newlabel{fig:linear_model}{{3.4a}{15}{The linear model of the lens.\relax }{figure.caption.33}{}}
\newlabel{sub@fig:linear_model}{{a}{15}{The linear model of the lens.\relax }{figure.caption.33}{}}
\newlabel{fig:tan_model}{{3.4b}{15}{The tangent model of the lens.\relax }{figure.caption.33}{}}
\newlabel{sub@fig:tan_model}{{b}{15}{The tangent model of the lens.\relax }{figure.caption.33}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Approximation of the calibration data by a linear and tangent model of the lens.\relax }}{15}{figure.caption.33}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Linear model}{15}{subsubsection.31}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Tangent model}{15}{subsubsection.34}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}The city coordinate system}{16}{subsection.36}}
\citation{krizhevsky2012imagenet}
\citation{lin2014microsoft}
\citation{krizhevsky2012imagenet}
\citation{lin2014microsoft}
\citation{krizhevsky2012imagenet}
\citation{lin2014microsoft}
\@writefile{toc}{\contentsline {section}{\numberline {4}Dataset generation}{17}{section.37}}
\newlabel{sec:classical}{{4}{17}{Dataset generation}{section.37}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Need for a custom dataset}{17}{subsection.38}}
\newlabel{fig:coco0}{{4.1a}{17}{Example of COCO photo for object detection.\relax }{figure.caption.39}{}}
\newlabel{sub@fig:coco0}{{a}{17}{Example of COCO photo for object detection.\relax }{figure.caption.39}{}}
\newlabel{fig:imagenet3}{{4.1b}{17}{Example of ImageNet photo for image classification.\relax }{figure.caption.39}{}}
\newlabel{sub@fig:imagenet3}{{b}{17}{Example of ImageNet photo for image classification.\relax }{figure.caption.39}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces The car class examples in ImageNet \cite  {krizhevsky2012imagenet} and COCO \cite  {lin2014microsoft}.\relax }}{17}{figure.caption.39}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Distributed system}{17}{subsection.40}}
\citation{piccardi2004background}
\citation{opencv}
\citation{wren1997pfinder}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Background subtraction detection}{18}{subsection.41}}
\newlabel{sec:bgs}{{4.3}{18}{Background subtraction detection}{subsection.41}{}}
\citation{bgs-med1,bgs-med2}
\newlabel{fig:cut_mean}{{4.2a}{19}{Mean model.\relax }{figure.caption.42}{}}
\newlabel{sub@fig:cut_mean}{{a}{19}{Mean model.\relax }{figure.caption.42}{}}
\newlabel{fig:cut_med}{{4.2b}{19}{Median model.\relax }{figure.caption.42}{}}
\newlabel{sub@fig:cut_med}{{b}{19}{Median model.\relax }{figure.caption.42}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Background model created by the mean and the median approach.\relax }}{19}{figure.caption.42}}
\newlabel{fig:threshold_mean}{{4.3a}{19}{Mean.\relax }{figure.caption.44}{}}
\newlabel{sub@fig:threshold_mean}{{a}{19}{Mean.\relax }{figure.caption.44}{}}
\newlabel{fig:threshold_med}{{4.3b}{19}{Median.\relax }{figure.caption.44}{}}
\newlabel{sub@fig:threshold_med}{{b}{19}{Median.\relax }{figure.caption.44}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces The difference between the frame and a background shown in a gray-scale.\relax }}{19}{figure.caption.44}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces The histogram of a particular pixel over 100 images with computed medians.\relax }}{20}{figure.caption.45}}
\newlabel{fig:pixel_hist}{{4.4}{20}{The histogram of a particular pixel over 100 images with computed medians.\relax }{figure.caption.45}{}}
\newlabel{fig:frame_for_detection}{{4.5a}{21}{A frame for detection.\relax }{figure.caption.46}{}}
\newlabel{sub@fig:frame_for_detection}{{a}{21}{A frame for detection.\relax }{figure.caption.46}{}}
\newlabel{fig:mask_area}{{4.5b}{21}{The detections and areas of contours.\relax }{figure.caption.46}{}}
\newlabel{sub@fig:mask_area}{{b}{21}{The detections and areas of contours.\relax }{figure.caption.46}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces The background subtraction detection algorithm.\relax }}{21}{figure.caption.46}}
\citation{opencv}
\citation{optical-flow}
\citation{lucas-kanede}
\citation{shi-tomasi}
\citation{harris}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Optical Flow tracking}{22}{subsection.47}}
\newlabel{sec:optical-flow}{{4.4}{22}{Optical Flow tracking}{subsection.47}{}}
\citation{haar}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Classification}{23}{subsection.48}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Semi-supervised dataset generation}{24}{subsection.49}}
\newlabel{sec:data-generation}{{4.6}{24}{Semi-supervised dataset generation}{subsection.49}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces The dialog from the annotation tool.\relax }}{24}{figure.caption.50}}
\newlabel{fig:labeling}{{4.6}{24}{The dialog from the annotation tool.\relax }{figure.caption.50}{}}
\citation{szegedy2016rethinking}
\citation{graves2013speech}
\citation{mit-vision}
\citation{rosenblatt1958perceptron}
\@writefile{toc}{\contentsline {section}{\numberline {5}Convolutional Neural Networks}{26}{section.51}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Inspiration by biology}{26}{subsection.52}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Layers}{26}{subsection.53}}
\citation{karpathy2016cs231n}
\citation{karpathy2016cs231n}
\citation{zeiler2014visualizing}
\citation{karpathy2016cs231n}
\citation{karpathy2016cs231n}
\citation{scherer2010evaluation}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Convolutional layer}{27}{subsection.54}}
\newlabel{fig:conv_layer}{{5.1a}{27}{An example of a convolutional layer.\relax }{figure.caption.55}{}}
\newlabel{sub@fig:conv_layer}{{a}{27}{An example of a convolutional layer.\relax }{figure.caption.55}{}}
\newlabel{fig:neuron}{{5.1b}{27}{Model of a neuron.\relax }{figure.caption.55}{}}
\newlabel{sub@fig:neuron}{{b}{27}{Model of a neuron.\relax }{figure.caption.55}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Examples of neural networks concepts from \cite  {karpathy2016cs231n}.\relax }}{27}{figure.caption.55}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}Pooling layer}{27}{subsubsection.56}}
\citation{blumer1989learnability}
\newlabel{fig:conv_layer}{{5.2a}{28}{Pooling downsamples the previous layer.\relax }{figure.caption.57}{}}
\newlabel{sub@fig:conv_layer}{{a}{28}{Pooling downsamples the previous layer.\relax }{figure.caption.57}{}}
\newlabel{fig:neuron}{{5.2b}{28}{Max pooling operation.\relax }{figure.caption.57}{}}
\newlabel{sub@fig:neuron}{{b}{28}{Max pooling operation.\relax }{figure.caption.57}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Examples of pooling concepts from \cite  {karpathy2016cs231n}.\relax }}{28}{figure.caption.57}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2}Fully connected layer}{28}{subsubsection.58}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.3}Overfitting and dropout layer}{28}{subsubsection.59}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Backpropagation}{28}{subsection.60}}
\newlabel{sec:back-prop}{{5.4}{28}{Backpropagation}{subsection.60}{}}
\citation{widrow199030}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Transfered learning}{29}{subsection.63}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6}Frameworks}{29}{subsection.64}}
\citation{abadi2016tensorflow}
\citation{bergstra2011theano}
\citation{seide2016cntk}
\citation{chollet2015keras}
\citation{jia2014caffe}
\citation{krizhevsky2012imagenet}
\citation{simonyan2014very}
\citation{simonyan2014very}
\citation{simonyan2014very}
\citation{redmon2016you}
\citation{barz2017fast}
\citation{liu2016ssd}
\citation{faster-rcnn}
\citation{ciresan2011flexible}
\citation{krizhevsky2012imagenet}
\citation{simonyan2014very}
\citation{krizhevsky2012imagenet}
\citation{zeiler2014visualizing}
\citation{lecun1989backpropagation}
\citation{simonyan2014very}
\citation{liu2016ssd}
\@writefile{toc}{\contentsline {section}{\numberline {6}Classification, Detection and Reidentification networks}{31}{section.65}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Neural networks for classification}{31}{subsection.66}}
\newlabel{sec:neural_networks_classification}{{6.1}{31}{Neural networks for classification}{subsection.66}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.1}VGG}{31}{subsubsection.67}}
\newlabel{sec:vgg}{{6.1.1}{31}{VGG}{subsubsection.67}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}SSD network for detection}{31}{subsection.69}}
\newlabel{sec:ssd}{{6.2}{31}{SSD network for detection}{subsection.69}{}}
\citation{liu2016ssd}
\citation{redmon2016you}
\citation{liu2016ssd}
\citation{redmon2016you}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces The different VGG architectures. The ReLU function is not shown for simplicity. \cite  {simonyan2014very}\relax }}{32}{figure.caption.68}}
\newlabel{fig:vgg}{{6.1}{32}{The different VGG architectures. The ReLU function is not shown for simplicity. \cite {simonyan2014very}\relax }{figure.caption.68}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.1}Architecture}{33}{subsubsection.70}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces Comparison of the SSD\cite  {liu2016ssd}(300x300) and YOLO\cite  {redmon2016you}(448x448) architectures.\relax }}{33}{figure.caption.71}}
\newlabel{fig:ssd_vs_yolo}{{6.2}{33}{Comparison of the SSD\cite {liu2016ssd}(300x300) and YOLO\cite {redmon2016you}(448x448) architectures.\relax }{figure.caption.71}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.2}Default boxes and aspect ratios}{33}{subsubsection.72}}
\citation{erhan2014scalable}
\citation{diez2011non}
\citation{diez2011non}
\newlabel{fig:ssd_detection}{{6.3a}{34}{SSD prediction.\relax }{figure.caption.73}{}}
\newlabel{sub@fig:ssd_detection}{{a}{34}{SSD prediction.\relax }{figure.caption.73}{}}
\newlabel{fig:ssd4}{{6.3b}{34}{8 $\times $ 8 feature map.\relax }{figure.caption.73}{}}
\newlabel{sub@fig:ssd4}{{b}{34}{8 $\times $ 8 feature map.\relax }{figure.caption.73}{}}
\newlabel{fig:ssd8}{{6.3c}{34}{The predicted offsets.\relax }{figure.caption.73}{}}
\newlabel{sub@fig:ssd8}{{c}{34}{The predicted offsets.\relax }{figure.caption.73}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces The background subtraction detection algorithm.\relax }}{34}{figure.caption.73}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Loss}{34}{subsection.74}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.3.1}Training}{34}{subsubsection.75}}
\citation{tan2005introduction}
\citation{schroff2015facenet}
\citation{schroff2015facenet}
\citation{schroff2015facenet}
\newlabel{fig:nms1}{{6.4a}{35}{Predictions before applying nms.\relax }{figure.caption.77}{}}
\newlabel{sub@fig:nms1}{{a}{35}{Predictions before applying nms.\relax }{figure.caption.77}{}}
\newlabel{fig:nms2}{{6.4b}{35}{Predictions after applying nms.\relax }{figure.caption.77}{}}
\newlabel{sub@fig:nms2}{{b}{35}{Predictions after applying nms.\relax }{figure.caption.77}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.4}{\ignorespaces Non maxima suppression\cite  {diez2011non} keeps a single prediction.\relax }}{35}{figure.caption.77}}
\newlabel{fig:nms}{{6.4}{35}{Non maxima suppression\cite {diez2011non} keeps a single prediction.\relax }{figure.caption.77}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Non maxima suppression}{35}{subsection.76}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5}Facenet for reidentification}{35}{subsection.78}}
\newlabel{sec:facenet}{{6.5}{35}{Facenet for reidentification}{subsection.78}{}}
\citation{zeiler2014visualizing}
\citation{szegedy2016rethinking}
\citation{szegedy2016rethinking}
\citation{wst2008deeply,taigman2014deepface}
\newlabel{fig:facenet_structure}{{6.5a}{36}{The model structure.\relax }{figure.caption.80}{}}
\newlabel{sub@fig:facenet_structure}{{a}{36}{The model structure.\relax }{figure.caption.80}{}}
\newlabel{fig:triplet_loss}{{6.5b}{36}{The learning objective.\relax }{figure.caption.80}{}}
\newlabel{sub@fig:triplet_loss}{{b}{36}{The learning objective.\relax }{figure.caption.80}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.5}{\ignorespaces The Facenet \cite  {schroff2015facenet}.\relax }}{36}{figure.caption.80}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.5.1}Architecture}{36}{subsubsection.79}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.5.2}Training}{36}{subsubsection.81}}
\citation{szegedy2016rethinking}
\citation{chen2017beyond}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6}Multi camera tracking}{37}{subsection.84}}
\newlabel{sec:multi-camera-tracking}{{6.6}{37}{Multi camera tracking}{subsection.84}{}}
\citation{he2017mask}
\citation{he2017mask}
\citation{he2017mask}
\@writefile{toc}{\contentsline {section}{\numberline {7}Implementation}{38}{section.85}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Mask R-CNN segmentation}{38}{subsection.86}}
\newlabel{sec:mask-rcnn}{{7.1}{38}{Mask R-CNN segmentation}{subsection.86}{}}
\newlabel{fig:mask-street-cam}{{7.1a}{38}{Mask R-CNN on a standard street camera.\relax }{figure.caption.87}{}}
\newlabel{sub@fig:mask-street-cam}{{a}{38}{Mask R-CNN on a standard street camera.\relax }{figure.caption.87}{}}
\newlabel{fig:mask-omni-cam}{{7.1b}{38}{Mask R-CNN on a fisheye has problems recognizing vehicles from the top.\relax }{figure.caption.87}{}}
\newlabel{sub@fig:mask-omni-cam}{{b}{38}{Mask R-CNN on a fisheye has problems recognizing vehicles from the top.\relax }{figure.caption.87}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces Examples of Mask R-CNN network \cite  {he2017mask}.\relax }}{38}{figure.caption.87}}
\newlabel{fig:facenet}{{7.1}{38}{Examples of Mask R-CNN network \cite {he2017mask}.\relax }{figure.caption.87}{}}
\citation{liu2016ssd}
\citation{faster-rcnn}
\citation{redmon2016you}
\citation{ssd_keras}
\citation{walt2011numpy}
\citation{opencv}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}SSD detector}{39}{subsection.88}}
\newlabel{sec:ssd-implementation}{{7.2}{39}{SSD detector}{subsection.88}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.2.1}Temporal difference}{39}{subsubsection.89}}
\citation{cao2018feature}
\newlabel{fig:td_frame}{{7.2a}{40}{A frame from the street camera.\relax }{figure.caption.90}{}}
\newlabel{sub@fig:td_frame}{{a}{40}{A frame from the street camera.\relax }{figure.caption.90}{}}
\newlabel{fig:td_black}{{7.2b}{40}{Temporal difference highlights moving objects.\relax }{figure.caption.90}{}}
\newlabel{sub@fig:td_black}{{b}{40}{Temporal difference highlights moving objects.\relax }{figure.caption.90}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.2}{\ignorespaces Temporal difference helps to detect moving objects.\relax }}{40}{figure.caption.90}}
\newlabel{fig:td}{{7.2}{40}{Temporal difference helps to detect moving objects.\relax }{figure.caption.90}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.2.2}Architecture}{40}{subsubsection.92}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.2.3}Dataset}{41}{subsubsection.93}}
\citation{deng2009imagenet}
\citation{lin2014microsoft}
\citation{real2017youtube}
\citation{kingma2014adam}
\citation{ssd_keras}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.2.4}Data augmentation}{42}{subsubsection.94}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.2.5}Training}{42}{subsubsection.95}}
\newlabel{fig:ssd_mAP}{{7.3a}{43}{The mean average precision on validation set.\relax }{figure.caption.96}{}}
\newlabel{sub@fig:ssd_mAP}{{a}{43}{The mean average precision on validation set.\relax }{figure.caption.96}{}}
\newlabel{fig:ssd_loss}{{7.3b}{43}{The loss on the training set.\relax }{figure.caption.96}{}}
\newlabel{sub@fig:ssd_loss}{{b}{43}{The loss on the training set.\relax }{figure.caption.96}{}}
\newlabel{fig:ssd_val_loss}{{7.3c}{43}{The loss on the validation set.\relax }{figure.caption.96}{}}
\newlabel{sub@fig:ssd_val_loss}{{c}{43}{The loss on the validation set.\relax }{figure.caption.96}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.3}{\ignorespaces The process of training the 4 channel input SSD network. The training was performed on the NVIDIA GeForce GTX 1080 for 4 days.\relax }}{43}{figure.caption.96}}
\newlabel{fig:ssd_training}{{7.3}{43}{The process of training the 4 channel input SSD network. The training was performed on the NVIDIA GeForce GTX 1080 for 4 days.\relax }{figure.caption.96}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Single camera tracking}{43}{subsection.97}}
\citation{shi-tomasi}
\citation{szegedy2016rethinking}
\citation{huang2007labeled}
\citation{wolf2011face}
\citation{szegedy2016rethinking}
\citation{huang2007labeled}
\citation{wolf2011face}
\citation{schroff2015facenet}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.1}Seeding}{44}{subsubsection.98}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.2}Displacement}{44}{subsubsection.99}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.3}Matching}{44}{subsubsection.100}}
\citation{facenet}
\newlabel{fig:facenet_table}{{7.4a}{45}{Mean VAL at $10^{-3}$ FAR.\relax }{figure.caption.102}{}}
\newlabel{sub@fig:facenet_table}{{a}{45}{Mean VAL at $10^{-3}$ FAR.\relax }{figure.caption.102}{}}
\newlabel{fig:triplet_loss}{{7.4b}{45}{Comparison of different DNN architectures.\relax }{figure.caption.102}{}}
\newlabel{sub@fig:triplet_loss}{{b}{45}{Comparison of different DNN architectures.\relax }{figure.caption.102}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.4}{\ignorespaces Comparison of various facenet\cite  {szegedy2016rethinking} base networks evaluated on Labeled faces in the wild\cite  {huang2007labeled} and YouTube faces\cite  {wolf2011face} datasets.\relax }}{45}{figure.caption.102}}
\newlabel{fig:facenet}{{7.4}{45}{Comparison of various facenet\cite {szegedy2016rethinking} base networks evaluated on Labeled faces in the wild\cite {huang2007labeled} and YouTube faces\cite {wolf2011face} datasets.\relax }{figure.caption.102}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4}Similarity}{45}{subsection.101}}
\newlabel{sec:similarity}{{7.4}{45}{Similarity}{subsection.101}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.4.1}Dataset}{45}{subsubsection.103}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.5}{\ignorespaces An example of a one object in a training set.\relax }}{46}{figure.caption.104}}
\newlabel{fig:facenet-labeling}{{7.5}{46}{An example of a one object in a training set.\relax }{figure.caption.104}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.4.2}Problems with the dataset}{46}{subsubsection.105}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.4.3}Improving the dataset}{47}{subsubsection.106}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.4.4}Training}{47}{subsubsection.107}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.6}{\ignorespaces Accuracy during the facenet training.\relax }}{47}{figure.caption.108}}
\newlabel{fig:facenet_training}{{7.6}{47}{Accuracy during the facenet training.\relax }{figure.caption.108}{}}
\citation{wold1987principal}
\citation{maaten2008visualizing}
\citation{pedregosa2011scikit}
\newlabel{fig:facenet}{{7.7a}{48}{True positive rate.\relax }{figure.caption.109}{}}
\newlabel{sub@fig:facenet}{{a}{48}{True positive rate.\relax }{figure.caption.109}{}}
\newlabel{fig:facenet}{{7.7b}{48}{True negative rate.\relax }{figure.caption.109}{}}
\newlabel{sub@fig:facenet}{{b}{48}{True negative rate.\relax }{figure.caption.109}{}}
\newlabel{fig:facenet}{{7.7c}{48}{False positive rate.\relax }{figure.caption.109}{}}
\newlabel{sub@fig:facenet}{{c}{48}{False positive rate.\relax }{figure.caption.109}{}}
\newlabel{fig:facenet}{{7.7d}{48}{False negative rate.\relax }{figure.caption.109}{}}
\newlabel{sub@fig:facenet}{{d}{48}{False negative rate.\relax }{figure.caption.109}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.7}{\ignorespaces Additional information about the Facenet training. The training was performed on the NVIDIA GeForce GTX 1080 for 12 hours.\relax }}{48}{figure.caption.109}}
\newlabel{fig:facenet_training_additional}{{7.7}{48}{Additional information about the Facenet training. The training was performed on the NVIDIA GeForce GTX 1080 for 12 hours.\relax }{figure.caption.109}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.4.5}T-SNE visualization}{48}{subsubsection.110}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.8}{\ignorespaces Visualization of facenet embeddings using the T-SNE dimensionality reduction.\relax }}{49}{figure.caption.111}}
\newlabel{fig:facenet_training}{{7.8}{49}{Visualization of facenet embeddings using the T-SNE dimensionality reduction.\relax }{figure.caption.111}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5}City representation}{49}{subsection.112}}
\newlabel{sec:city-representation}{{7.5}{49}{City representation}{subsection.112}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.9}{\ignorespaces An example of a part of city representation with transition probabilities.\relax }}{50}{figure.caption.113}}
\newlabel{fig:intersection}{{7.9}{50}{An example of a part of city representation with transition probabilities.\relax }{figure.caption.113}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.5.1}Reidentification}{51}{subsubsection.114}}
\newlabel{sec:reidentification}{{7.5.1}{51}{Reidentification}{subsubsection.114}{}}
\newlabel{eq:score-reid}{{16}{51}{Reidentification}{equation.115}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.5.2}Decreasing computational demands}{51}{subsubsection.116}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.6}Multi camera tracking}{52}{subsection.118}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Evaluation}{53}{section.119}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Mean average precision.}{53}{subsection.120}}
\newlabel{sec:mAP}{{8.1}{53}{Mean average precision}{subsection.120}{}}
\citation{liu2016ssd}
\@writefile{lof}{\contentsline {figure}{\numberline {8.1}{\ignorespaces Example of precision-recall curve.\relax }}{54}{figure.caption.124}}
\newlabel{fig:precision-recall}{{8.1}{54}{Example of precision-recall curve.\relax }{figure.caption.124}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}SSD object detection}{54}{subsection.125}}
\newlabel{sec:ssd-evaluation}{{8.2}{54}{SSD object detection}{subsection.125}{}}
\newlabel{fig:ssd_mAP}{{8.2a}{55}{The mean average precision on validation set.\relax }{figure.caption.126}{}}
\newlabel{sub@fig:ssd_mAP}{{a}{55}{The mean average precision on validation set.\relax }{figure.caption.126}{}}
\newlabel{fig:ssd_loss}{{8.2b}{55}{The loss on the training set.\relax }{figure.caption.126}{}}
\newlabel{sub@fig:ssd_loss}{{b}{55}{The loss on the training set.\relax }{figure.caption.126}{}}
\newlabel{fig:ssd_val_loss}{{8.2c}{55}{The loss on the validation set.\relax }{figure.caption.126}{}}
\newlabel{sub@fig:ssd_val_loss}{{c}{55}{The loss on the validation set.\relax }{figure.caption.126}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.2}{\ignorespaces The process of training the introduced 4 channel SSD (orange) and the 3 channel SSD (blue) networks. The training was performed on the NVIDIA GeForce GTX 1080 for 1 day. The graph shows, that the presented solution performs much better than the state of the art SSD.\relax }}{55}{figure.caption.126}}
\newlabel{fig:ssd_training}{{8.2}{55}{The process of training the introduced 4 channel SSD (orange) and the 3 channel SSD (blue) networks. The training was performed on the NVIDIA GeForce GTX 1080 for 1 day. The graph shows, that the presented solution performs much better than the state of the art SSD.\relax }{figure.caption.126}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Results on the custom dataset from the section \ref  {sec:ssd-dataset} show, that the introduced RGBD architecture is more accurate, than the standard SSD.\relax }}{56}{table.caption.127}}
\newlabel{tab:ssd_camparison}{{2}{56}{Results on the custom dataset from the section \ref {sec:ssd-dataset} show, that the introduced RGBD architecture is more accurate, than the standard SSD.\relax }{table.caption.127}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3}Facenet similarity}{56}{subsection.128}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.3.1}Evaluation metrics}{56}{subsubsection.129}}
\newlabel{sec:similarity-eval}{{8.3.1}{56}{Evaluation metrics}{subsubsection.129}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.3.2}Results}{56}{subsubsection.130}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Final results of the facenet training after 12 hours on NVIDIA GeForce GTX 1080.\relax }}{56}{table.caption.131}}
\newlabel{tab:facenet}{{3}{56}{Final results of the facenet training after 12 hours on NVIDIA GeForce GTX 1080.\relax }{table.caption.131}{}}
\citation{munroe2005multi,psyllos2011vehicle,lai2001vehicle}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.3.3}Comparison to state of the art}{57}{subsubsection.132}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.4}Multi camera tracking experiment}{57}{subsection.133}}
\newlabel{sec:multi-camera-tracking}{{8.4}{57}{Multi camera tracking experiment}{subsection.133}{}}
\citation{coifman2007vehicle,kuhne1991freeway}
\citation{arth2007real,du2013automatic}
\citation{matei2011vehicle}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.4.1}Evaluation measurement}{58}{subsubsection.134}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.4.2}Results}{58}{subsubsection.135}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.4.3}Comparison to state of the art}{58}{subsubsection.136}}
\@writefile{toc}{\contentsline {section}{\numberline {9}Discussion}{59}{section.137}}
\citation{liu2016ssd}
\citation{liu2016ssd}
\citation{schroff2015facenet}
\@writefile{toc}{\contentsline {section}{\numberline {10}Conclusion}{60}{section.138}}
\citation{chen2017beyond}
\citation{lin2017focal,redmon2018yolov3}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1}Future work}{61}{subsection.139}}
\bibstyle{plain}
\bibdata{src/ref}
\bibcite{abadi2016tensorflow}{{1}{}{{}}{{}}}
\bibcite{arth2007real}{{2}{}{{}}{{}}}
\bibcite{banerjee2008multi}{{3}{}{{}}{{}}}
\bibcite{barz2017fast}{{4}{}{{}}{{}}}
\bibcite{bayona2010stationary}{{5}{}{{}}{{}}}
\bibcite{optical-flow}{{6}{}{{}}{{}}}
\bibcite{benfold2011stable}{{7}{}{{}}{{}}}
\bibcite{bergstra2011theano}{{8}{}{{}}{{}}}
\bibcite{bertinetto2016fully}{{9}{}{{}}{{}}}
\bibcite{bertozzi2000stereo}{{10}{}{{}}{{}}}
\bibcite{bicego2006use}{{11}{}{{}}{{}}}
\bibcite{blumer1989learnability}{{12}{}{{}}{{}}}
\bibcite{boiman2008defense}{{13}{}{{}}{{}}}
\bibcite{bosch2007image}{{14}{}{{}}{{}}}
\bibcite{opencv}{{15}{}{{}}{{}}}
\bibcite{cao2018feature}{{16}{}{{}}{{}}}
\bibcite{ncarlevaris-2015a}{{17}{}{{}}{{}}}
\bibcite{carreira2012cpmc}{{18}{}{{}}{{}}}
\bibcite{caruso1999vehicle}{{19}{}{{}}{{}}}
\bibcite{chapelle1999support}{{20}{}{{}}{{}}}
\bibcite{chen2017beyond}{{21}{}{{}}{{}}}
\bibcite{chen2011tracking}{{22}{}{{}}{{}}}
\bibcite{chollet2015keras}{{23}{}{{}}{{}}}
\bibcite{ciresan2011flexible}{{24}{}{{}}{{}}}
\bibcite{coifman2007vehicle}{{25}{}{{}}{{}}}
\bibcite{comaniciu2003kernel}{{26}{}{{}}{{}}}
\bibcite{bgs-med2}{{27}{}{{}}{{}}}
\bibcite{dai2016r}{{28}{}{{}}{{}}}
\bibcite{dalal2005histograms}{{29}{}{{}}{{}}}
\bibcite{daubaras2012vehicle}{{30}{}{{}}{{}}}
\bibcite{deng2009imagenet}{{31}{}{{}}{{}}}
\bibcite{diez2011non}{{32}{}{{}}{{}}}
\bibcite{du2013automatic}{{33}{}{{}}{{}}}
\bibcite{elgammal2002background}{{34}{}{{}}{{}}}
\bibcite{erhan2014scalable}{{35}{}{{}}{{}}}
\bibcite{Everingham10}{{36}{}{{}}{{}}}
\bibcite{felzenszwalb2010object}{{37}{}{{}}{{}}}
\bibcite{facenet}{{38}{}{{}}{{}}}
\bibcite{ssd_keras}{{39}{}{{}}{{}}}
\bibcite{gaidon2016virtual}{{40}{}{{}}{{}}}
\bibcite{gate2009fast}{{41}{}{{}}{{}}}
\bibcite{cisco}{{42}{}{{}}{{}}}
\bibcite{girshick2015fast}{{43}{}{{}}{{}}}
\bibcite{girshick2014rich}{{44}{}{{}}{{}}}
\bibcite{girshick2016region}{{45}{}{{}}{{}}}
\bibcite{DBLP:journals/corr/GirshickDDM13}{{46}{}{{}}{{}}}
\bibcite{gladh2016deep}{{47}{}{{}}{{}}}
\bibcite{gonzalez2012digital}{{48}{}{{}}{{}}}
\bibcite{graves2013speech}{{49}{}{{}}{{}}}
\bibcite{harris}{{50}{}{{}}{{}}}
\bibcite{haar}{{51}{}{{}}{{}}}
\bibcite{he2017mask}{{52}{}{{}}{{}}}
\bibcite{he2016deep}{{53}{}{{}}{{}}}
\bibcite{held2016learning}{{54}{}{{}}{{}}}
\bibcite{horprasert1999statistical}{{55}{}{{}}{{}}}
\bibcite{huang2017densely}{{56}{}{{}}{{}}}
\bibcite{huang2007labeled}{{57}{}{{}}{{}}}
\bibcite{huang1997object}{{58}{}{{}}{{}}}
\bibcite{apollo-scape}{{59}{}{{}}{{}}}
\bibcite{isard2001bramble}{{60}{}{{}}{{}}}
\bibcite{javed2005appearance}{{61}{}{{}}{{}}}
\bibcite{jia2014caffe}{{62}{}{{}}{{}}}
\bibcite{joshi2012survey}{{63}{}{{}}{{}}}
\bibcite{kale2015moving}{{64}{}{{}}{{}}}
\bibcite{kang2003continuous}{{65}{}{{}}{{}}}
\bibcite{karpathy2016cs231n}{{66}{}{{}}{{}}}
\bibcite{karpathy2014large}{{67}{}{{}}{{}}}
\bibcite{kettnaker1999bayesian}{{68}{}{{}}{{}}}
\bibcite{khan2003consistent}{{69}{}{{}}{{}}}
\bibcite{kim2005front}{{70}{}{{}}{{}}}
\bibcite{kingma2014adam}{{71}{}{{}}{{}}}
\bibcite{koprinska2001temporal}{{72}{}{{}}{{}}}
\bibcite{krizhevsky2012imagenet}{{73}{}{{}}{{}}}
\bibcite{krumm2000multi}{{74}{}{{}}{{}}}
\bibcite{kuhne1991freeway}{{75}{}{{}}{{}}}
\bibcite{kwong2009arterial}{{76}{}{{}}{{}}}
\bibcite{lai2001vehicle}{{77}{}{{}}{{}}}
\bibcite{lazebnik2006beyond}{{78}{}{{}}{{}}}
\bibcite{lecun1989backpropagation}{{79}{}{{}}{{}}}
\bibcite{lecun1998gradient}{{80}{}{{}}{{}}}
\bibcite{lecun-mnisthandwrittendigit-2010}{{81}{}{{}}{{}}}
\bibcite{lee2016globally}{{82}{}{{}}{{}}}
\bibcite{li2017fssd}{{83}{}{{}}{{}}}
\bibcite{lienhart2002extended}{{84}{}{{}}{{}}}
\bibcite{lin2017focal}{{85}{}{{}}{{}}}
\bibcite{lin2014microsoft}{{86}{}{{}}{{}}}
\bibcite{liu2016ssd}{{87}{}{{}}{{}}}
\bibcite{bgs-med1}{{88}{}{{}}{{}}}
\bibcite{lowe2004distinctive}{{89}{}{{}}{{}}}
\bibcite{lucas-kanede}{{90}{}{{}}{{}}}
\bibcite{maaten2008visualizing}{{91}{}{{}}{{}}}
\bibcite{RobotCarDatasetIJRR}{{92}{}{{}}{{}}}
\bibcite{madhavan2017bdd}{{93}{}{{}}{{}}}
\bibcite{mae1996object}{{94}{}{{}}{{}}}
\bibcite{makris2004bridging}{{95}{}{{}}{{}}}
\bibcite{matei2011vehicle}{{96}{}{{}}{{}}}
\bibcite{munder2006experimental}{{97}{}{{}}{{}}}
\bibcite{munroe2005multi}{{98}{}{{}}{{}}}
\bibcite{naoya1990optical}{{99}{}{{}}{{}}}
\bibcite{nowak2006sampling}{{100}{}{{}}{{}}}
\bibcite{opelt2004weak}{{101}{}{{}}{{}}}
\bibcite{pedregosa2011scikit}{{102}{}{{}}{{}}}
\bibcite{piccardi2004background}{{103}{}{{}}{{}}}
\bibcite{porikli2003inter}{{104}{}{{}}{{}}}
\bibcite{porikli2005multi}{{105}{}{{}}{{}}}
\bibcite{premebida2007lidar}{{106}{}{{}}{{}}}
\bibcite{psyllos2011vehicle}{{107}{}{{}}{{}}}
\bibcite{quenot1992orthogonal}{{108}{}{{}}{{}}}
\bibcite{rahimi2004simultaneous}{{109}{}{{}}{{}}}
\bibcite{real2017youtube}{{110}{}{{}}{{}}}
\bibcite{redmon2016you}{{111}{}{{}}{{}}}
\bibcite{redmon2017yolo9000}{{112}{}{{}}{{}}}
\bibcite{redmon2018yolov3}{{113}{}{{}}{{}}}
\bibcite{faster-rcnn}{{114}{}{{}}{{}}}
\bibcite{rosenblatt1958perceptron}{{115}{}{{}}{{}}}
\bibcite{scherer2010evaluation}{{116}{}{{}}{{}}}
\bibcite{schroff2015facenet}{{117}{}{{}}{{}}}
\bibcite{seide2016cntk}{{118}{}{{}}{{}}}
\bibcite{shi-tomasi}{{119}{}{{}}{{}}}
\bibcite{simonyan2014very}{{120}{}{{}}{{}}}
\bibcite{sudowe2011efficient}{{121}{}{{}}{{}}}
\bibcite{sun2002real}{{122}{}{{}}{{}}}
\bibcite{mit-vision}{{123}{}{{}}{{}}}
\bibcite{szegedy2016rethinking}{{124}{}{{}}{{}}}
\bibcite{taigman2014deepface}{{125}{}{{}}{{}}}
\bibcite{tan2005introduction}{{126}{}{{}}{{}}}
\bibcite{toulminet2006vehicle}{{127}{}{{}}{{}}}
\bibcite{tzomakas1998vehicle}{{128}{}{{}}{{}}}
\bibcite{veenman1998fast}{{129}{}{{}}{{}}}
\bibcite{viola2004robust}{{130}{}{{}}{{}}}
\bibcite{walt2011numpy}{{131}{}{{}}{{}}}
\bibcite{wang2003online}{{132}{}{{}}{{}}}
\bibcite{wang2009hog}{{133}{}{{}}{{}}}
\bibcite{wender20083d}{{134}{}{{}}{{}}}
\bibcite{widrow199030}{{135}{}{{}}{{}}}
\bibcite{wold1987principal}{{136}{}{{}}{{}}}
\bibcite{wolf2011face}{{137}{}{{}}{{}}}
\bibcite{wren1997pfinder}{{138}{}{{}}{{}}}
\bibcite{wst2008deeply}{{139}{}{{}}{{}}}
\bibcite{xie2017aggregated}{{140}{}{{}}{{}}}
\bibcite{yang2009linear}{{141}{}{{}}{{}}}
\bibcite{yilmaz2007object}{{142}{}{{}}{{}}}
\bibcite{yilmaz2006object}{{143}{}{{}}{{}}}
\bibcite{zagoruyko2016wide}{{144}{}{{}}{{}}}
\bibcite{zeiler2014visualizing}{{145}{}{{}}{{}}}
\bibcite{zhang2006svm}{{146}{}{{}}{{}}}
\bibcite{zhao2005real}{{147}{}{{}}{{}}}
\bibcite{zhong2012moving}{{148}{}{{}}{{}}}
\bibcite{zhu2006fast}{{149}{}{{}}{{}}}
\newlabel{LastPage}{{}{76}{}{page.92}{}}
\xdef\lastpage@lastpage{76}
\xdef\lastpage@lastpageHy{92}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
